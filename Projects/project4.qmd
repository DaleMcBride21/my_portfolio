---
title: "Client Report - Project 4"
subtitle: "Course DS 250"
author: "Dale McBride"
format:
  html:
    self-contained: true
    page-layout: full
    title-block-banner: true
    toc: true
    toc-depth: 3
    toc-location: body
    number-sections: false
    html-math-method: katex
    code-fold: true
    code-summary: "Show the code"
    code-overflow: wrap
    code-copy: hover
    code-tools:
        source: false
        toggle: true
        caption: See code
execute: 
  warning: false
    
---

```{python}
#| label: libraries
#| include: false
import pandas as pd
import numpy as np
import plotly.express as px
```

```{python}
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn import tree
from sklearn import metrics
```


## Elevator pitch

_paste your elevator pitch here_
_A SHORT (4-5 SENTENCES) PARAGRAPH THAT `DESCRIBES KEY INSIGHTS` TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS._

```{python}
#| label: project data
#| code-summary: Read and format project data
# Include and execute your code here
df = pd.read_csv("https://raw.githubusercontent.com/byuidatascience/data4dwellings/master/data-raw/dwellings_ml/dwellings_ml.csv")
```

__Highlight the Questions and Tasks__

## QUESTION|TASK 1

__Create 2-3 charts that evaluate potential relationships between the home variables and before1980. Explain what you learn from the charts that could help a machine learning algorithm.__

_After 1980, there is a noticeable rise in both the livable space density and the net price of homes, suggesting a possible correlation between the construction year and the size and cost of the properties. The first scatter plot shows a corrolation between the liveable area and the year that it was built. The number of houses larger than 5000 square feet built after 1980 significantly increases. Showing a corrolation between house size and the year built. The second chart compares the net price and the year that it is built. Showing that if the netprice is higher than it is likely that the house was built after 1980._


```{python}
#| label: Q1 chart 1
#| code-summary: plot example
#| fig-align: center
# Include and execute your code here
subset = df.filter(['before1980', 'yrbuilt', 'netprice', 'smonth', 'livearea', 'deduct', 'stories', 'livearea',])

subset['color'] = subset['before1980'].apply(lambda x: 'Before 1980' if x else 'After 1980')

color_map_labels = {'Before 1980': 'blue', 'After 1980': 'red'}

chart = px.scatter(subset,
    title='Liveable Area versus house build year',
    x="yrbuilt", 
    y="livearea",
    color="color",
    color_discrete_map=color_map_labels
)

chart.update_layout(
    xaxis_title="Year Built",
    yaxis_title="Liveable Area"
)

chart.show()
```

_The chart shows a siginificant increase in quantity of homes with higher amounts of liveable area in them after 1980._

```{python}
#| label: Q1 chart 2
#| code-summary: plot example
#| fig-align: center
# Include and execute your code here

subset = df.filter(['before1980', 'yrbuilt', 'netprice', 'numbdrm', 'numbaths', 'nocars'])

subset['color'] = subset['before1980'].apply(lambda x: 'Before 1980' if x else 'After 1980')

color_map_labels = {'Before 1980': 'blue', 'After 1980': 'red'}

chart = px.scatter(subset,
    title="Comparing Net price and Build Year",
    x="yrbuilt", 
    y="netprice",
    color="color",
    color_discrete_map=color_map_labels

)

chart.update_layout(
    xaxis_title="Year Built",
    yaxis_title="Net Price"
)

chart.show()
```

_This chart also shows an increase in the quantity of more expensive homes after the year of 1980. There are a few outliers in the data prior to 1980, but not enough to change the data._

## QUESTION|TASK 2

__Build a classification model labeling houses as being built “before 1980” or “during or after 1980”. Your goal is to reach or exceed 90% accuracy. Explain your final model choice (algorithm, tuning parameters, etc) and describe what other models you tried.__

_Report 2 exhibits the highest performance across all evaluation metrics, boasting the highest accuracy, precision, recall, and F1-score among the three models evaluated. With precision and recall scores of 0.90 and 0.94 for Class 0 and Class 1 respectively, Report 2 demonstrates its effectiveness in correctly identifying both positive and negative instances. The balanced F1-score of 0.90 and 0.94 for Class 0 and Class 1 further confirms the model's ability to maintain a trade-off between precision and recall. Overall, Report 2 emerges as the most robust classifier, showcasing superior predictive capability on the dataset._

```{python}
#| label: Q2
#| code-summary: Read and format data
# Include and execute your code here

X_pred = df.drop(df.filter(regex = 'before1980|yrbuilt|parcel').columns, axis = 1)

y_pred = df.filter(regex = "before1980")

X_train, X_test, y_train, y_test = train_test_split(
    X_pred, y_pred, test_size = .32, random_state = 78)


```

```{python}
#| label: chart
clf = tree.DecisionTreeClassifier()
clf = clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
y_probs = clf.predict_proba(X_test)
```

```{python}
print(metrics.classification_report(y_test, y_pred))
```

```{python}
clf = RandomForestClassifier()
clf = clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
y_probs = clf.predict_proba(X_test)
#evaluate the difference between the two
```

```{python}
print(metrics.classification_report(y_test, y_pred))
```

```{python}
clf = GradientBoostingClassifier()
clf = clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
y_probs = clf.predict_proba(X_test)
```

```{python}
print(metrics.classification_report(y_test, y_pred))
```



## QUESTION|TASK 3

__Justify your classification model by discussing the most important features selected by your model. This discussion should include a chart and a description of the features.__

_The most important features are listed by their importance values in descending order. The graphic gives another look at the importance values. The decision tree uses arcstyle_ONE-STORY to base a lot of its predictions as well as gartype_Att, quality_C and livearea._

```{python}
# feature_importance = clf.feature_importances_
# feature_names = X_train.columns

# # Create a dictionary to associate feature names with their importance values
# feature_importance_dict = dict(zip(feature_names, feature_importance))

# # Sort the dictionary by importance values in descending order
# sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)

# # Display the top features and their importance values
# for feature, importance in sorted_feature_importance:
#     print(f"Feature: {feature}, Importance: {importance}")
```


```{python}
#| label: Q3
#| code-summary: Read and format data
# Include and execute your code here
df_features = pd.DataFrame(
    {'f_names': X_train.columns, 
    'f_values': clf.feature_importances_}).sort_values('f_values', ascending = False)

    #what does before 1980 have to do with the top value in the bar chart
```


```{python}
#| label: Q3 feature importance chart!!!!
#| code-summary: plot example
#| fig-align: center
# Include and execute your code here
chart = px.bar(df_features.head(10),
    x='f_values', 
    y='f_names'
)

chart.update_layout(yaxis={'categoryorder':'total ascending'})
```


## QUESTION|TASK 4

__Describe the quality of your classification model using 2-3 different evaluation metrics. You also need to explain how to interpret each of the evaluation metrics you use.__

_The quality of the model is on the high end by having an accuracy of 90%, a precisinon of 90% and a recall of 90%. Having 90% of the houses correctly classified is really good. 90% of the houses that are labeled as built before 1980 are actually built before 1980. As well as correctly identifying 90% of the houses built before 1980._

```{python}
#| label: Q4
#| code-summary: Read and format data
# Include and execute your code here
print(metrics.classification_report(y_test, y_pred))

```

The second half of each questions(give more of an explaination), use a different algorithm and compare the two of them, elevator pitch, check for misspellings