[
  {
    "objectID": "story_telling.html",
    "href": "story_telling.html",
    "title": "About Me",
    "section": "",
    "text": "Introduction\n\nMy name is Dale McBride, I am from a small town in Wyoming called Otto. I have always been interested in computers and have chosen to study Computer Science.\nI have always been active in Student Council as well as sports my entire life. Basketball is my favorite, but I also liked Football and Track.\nSome of my other interests are hunting and fishing. Generally, if it is outdoors I will like to do it.\n\nMarkDown Basics\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "DS250 Projects",
    "section": "",
    "text": "Project 1\nProject 2\nProject 3\nProject 4\nProject 5"
  },
  {
    "objectID": "projects.html#repo-for-all-my-projects",
    "href": "projects.html#repo-for-all-my-projects",
    "title": "DS250 Projects",
    "section": "",
    "text": "Project 1\nProject 2\nProject 3\nProject 4\nProject 5"
  },
  {
    "objectID": "Projects/project4.html",
    "href": "Projects/project4.html",
    "title": "Client Report - Project 4",
    "section": "",
    "text": "Code\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import tree\nfrom sklearn import metrics"
  },
  {
    "objectID": "Projects/project4.html#elevator-pitch",
    "href": "Projects/project4.html#elevator-pitch",
    "title": "Client Report - Project 4",
    "section": "Elevator pitch",
    "text": "Elevator pitch\npaste your elevator pitch here A SHORT (4-5 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://raw.githubusercontent.com/byuidatascience/data4dwellings/master/data-raw/dwellings_ml/dwellings_ml.csv\")\n\n\nHighlight the Questions and Tasks"
  },
  {
    "objectID": "Projects/project4.html#questiontask-1",
    "href": "Projects/project4.html#questiontask-1",
    "title": "Client Report - Project 4",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nCreate 2-3 charts that evaluate potential relationships between the home variables and before1980. Explain what you learn from the charts that could help a machine learning algorithm.\nAfter 1980, there is a noticeable rise in both the livable space density and the net price of homes, suggesting a possible correlation between the construction year and the size and cost of the properties.\n\n\nplot example\n# Include and execute your code here\nsubset = df.filter(['before1980', 'yrbuilt', 'netprice', 'smonth', 'livearea', 'deduct', 'stories', 'livearea',])\n\nsubset['color'] = subset['before1980'].apply(lambda x: 'Before 1980' if x else 'After 1980')\n\ncolor_map_labels = {'Before 1980': 'blue', 'After 1980': 'red'}\n\nchart = px.scatter(subset,\n    title='Liveable Area versus house build year',\n    x=\"yrbuilt\", \n    y=\"livearea\",\n    color=\"color\",\n    color_discrete_map=color_map_labels\n)\n\nchart.update_layout(\n    xaxis_title=\"Year Built\",\n    yaxis_title=\"Liveable Area\"\n)\n\nchart.show()\n\n\n\n                                                \n\n\nThe chart shows a siginificant increase in quantity of homes with higher amounts of liveable area in them after 1980.\n\n\nplot example\n# Include and execute your code here\n\nsubset = df.filter(['before1980', 'yrbuilt', 'netprice', 'numbdrm', 'numbaths', 'nocars'])\n\nsubset['color'] = subset['before1980'].apply(lambda x: 'Before 1980' if x else 'After 1980')\n\ncolor_map_labels = {'Before 1980': 'blue', 'After 1980': 'red'}\n\nchart = px.scatter(subset,\n    title=\"Comparing Net price and Build Year\",\n    x=\"yrbuilt\", \n    y=\"netprice\",\n    color=\"color\",\n    color_discrete_map=color_map_labels\n\n)\n\nchart.update_layout(\n    xaxis_title=\"Year Built\",\n    yaxis_title=\"Net Price\"\n)\n\nchart.show()\n\n\n\n                                                \n\n\nThis chart also shows an increase in the quantity of more expensive homes after the year of 1980. There are a few outliers in the data prior to 1980, but not enough to change the data."
  },
  {
    "objectID": "Projects/project4.html#questiontask-2",
    "href": "Projects/project4.html#questiontask-2",
    "title": "Client Report - Project 4",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nBuild a classification model labeling houses as being built “before 1980” or “during or after 1980”. Your goal is to reach or exceed 90% accuracy. Explain your final model choice (algorithm, tuning parameters, etc) and describe what other models you tried.\nThe model below achieves a accuracy of 90%. Although houses that were built before 1980 it has a little bit harder time predicting the right value. On the other hand it does very well predicting houses built during or after 1980. Scoring above 90% in all of the categories of Precision, Recall, F1-score, and Support.\n\n\nRead and format data\n# Include and execute your code here\n\nX_pred = df.drop(df.filter(regex = 'before1980|yrbuilt|parcel').columns, axis = 1)\n\ny_pred = df.filter(regex = \"before1980\")\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X_pred, y_pred, test_size = .32, random_state = 78)\n\n\ninclude figures in chunks and discuss your findings in the figure.\n\n\nCode\nclf = tree.DecisionTreeClassifier()\nclf = clf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\ny_probs = clf.predict_proba(X_test)\n\n\n\n\nCode\nprint(metrics.classification_report(y_test, y_pred))\n\n\n              precision    recall  f1-score   support\n\n           0       0.86      0.90      0.88      2713\n           1       0.94      0.91      0.92      4620\n\n    accuracy                           0.91      7333\n   macro avg       0.90      0.90      0.90      7333\nweighted avg       0.91      0.91      0.91      7333"
  },
  {
    "objectID": "Projects/project4.html#questiontask-3",
    "href": "Projects/project4.html#questiontask-3",
    "title": "Client Report - Project 4",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nJustify your classification model by discussing the most important features selected by your model. This discussion should include a chart and a description of the features.\nThe most important features are listed by their importance values in descending order. The graphic gives another look at the importance values. The decision tree uses arcstyle_ONE-STORY to base a lot of its predictions as well as gartype_Att, quality_C and livearea.\n\n\nCode\n# feature_importance = clf.feature_importances_\n# feature_names = X_train.columns\n\n# # Create a dictionary to associate feature names with their importance values\n# feature_importance_dict = dict(zip(feature_names, feature_importance))\n\n# # Sort the dictionary by importance values in descending order\n# sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n\n# # Display the top features and their importance values\n# for feature, importance in sorted_feature_importance:\n#     print(f\"Feature: {feature}, Importance: {importance}\")\n\n\n\n\nRead and format data\n# Include and execute your code here\ndf_features = pd.DataFrame(\n    {'f_names': X_train.columns, \n    'f_values': clf.feature_importances_}).sort_values('f_values', ascending = False)\n\n\ninclude figures in chunks and discuss your findings in the figure.\n\n\nplot example\n# Include and execute your code here\nchart = px.bar(df_features.head(10),\n    x='f_values', \n    y='f_names'\n)\n\nchart.update_layout(yaxis={'categoryorder':'total ascending'})"
  },
  {
    "objectID": "Projects/project4.html#questiontask-4",
    "href": "Projects/project4.html#questiontask-4",
    "title": "Client Report - Project 4",
    "section": "QUESTION|TASK 4",
    "text": "QUESTION|TASK 4\nDescribe the quality of your classification model using 2-3 different evaluation metrics. You also need to explain how to interpret each of the evaluation metrics you use.\nThe quality of the model is on the high end by having an accuracy of 90%, a precisinon of 90% and a recall of 90%. Having 90% of the houses correctly classified is really good. 90% of the houses that are lebeld as built before 1980 are actually bulit before 1980. As well as correctly identifying 90% of the houses built before 1980.\n\n\nRead and format data\n# Include and execute your code here\nprint(metrics.classification_report(y_test, y_pred))\n\n\n              precision    recall  f1-score   support\n\n           0       0.86      0.90      0.88      2713\n           1       0.94      0.91      0.92      4620\n\n    accuracy                           0.91      7333\n   macro avg       0.90      0.90      0.90      7333\nweighted avg       0.91      0.91      0.91      7333"
  },
  {
    "objectID": "Projects/project2.html",
    "href": "Projects/project2.html",
    "title": "Client Report - Project 2",
    "section": "",
    "text": "After looking through the flight data there are some issues that are apparent with flight delays. We can see that there are disparities in performance between the different airports. These insights shed light on airports grappling with higher rates of delays, allowing us to pinpoint areas for improvement.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_json(\"https://raw.githubusercontent.com/byuidatascience/data4missing/master/data-raw/flights_missing/flights_missing.json\")\n\n\nHighlight the Questions and Tasks"
  },
  {
    "objectID": "Projects/project2.html#elevator-pitch",
    "href": "Projects/project2.html#elevator-pitch",
    "title": "Client Report - Project 2",
    "section": "",
    "text": "After looking through the flight data there are some issues that are apparent with flight delays. We can see that there are disparities in performance between the different airports. These insights shed light on airports grappling with higher rates of delays, allowing us to pinpoint areas for improvement.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_json(\"https://raw.githubusercontent.com/byuidatascience/data4missing/master/data-raw/flights_missing/flights_missing.json\")\n\n\nHighlight the Questions and Tasks"
  },
  {
    "objectID": "Projects/project2.html#questiontask-1",
    "href": "Projects/project2.html#questiontask-1",
    "title": "Client Report - Project 2",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nFix all of the varied missing data types in the data to be consistent (all missing values should be displayed as “NaN”). In your report include one record example (one row) from your new data, in the raw JSON format. Your example should display the “NaN” for at least one missing value.\nBy replacing all of the missing or abnormal values it preps the dataset to be ready to be manipulated for the next tasks.\n\n\nRead and format data\n# Include and execute your code here\n\n#this just shows me the top of the dataframe to start out with\ndf.head(20)\n\n#this shows me how many items in what columns need to be replaced\nmissing_values = [-999, \"\", 'n/a', np.NaN]\nmissing = df.isin(missing_values).sum()\n\n\n#this replaces all of the missing values that are in the list above as \"NaN\"\nmissing = df.isin(missing_values)\nfill_nan_df = df.mask(missing, \"NaN\")\n\n\n\n\ntable example\n# Include and execute your code here\nmydat = fill_nan_df.head(1)\n\njson_data = mydat.to_json()\njson_data\n\n\n'{\"airport_code\":{\"0\":\"ATL\"},\"airport_name\":{\"0\":\"Atlanta, GA: Hartsfield-Jackson Atlanta International\"},\"month\":{\"0\":\"January\"},\"year\":{\"0\":2005.0},\"num_of_flights_total\":{\"0\":35048},\"num_of_delays_carrier\":{\"0\":\"1500+\"},\"num_of_delays_late_aircraft\":{\"0\":\"NaN\"},\"num_of_delays_nas\":{\"0\":4598},\"num_of_delays_security\":{\"0\":10},\"num_of_delays_weather\":{\"0\":448},\"num_of_delays_total\":{\"0\":8355},\"minutes_delayed_carrier\":{\"0\":116423.0},\"minutes_delayed_late_aircraft\":{\"0\":104415},\"minutes_delayed_nas\":{\"0\":207467.0},\"minutes_delayed_security\":{\"0\":297},\"minutes_delayed_weather\":{\"0\":36931},\"minutes_delayed_total\":{\"0\":465533}}'"
  },
  {
    "objectID": "Projects/project2.html#questiontask-2",
    "href": "Projects/project2.html#questiontask-2",
    "title": "Client Report - Project 2",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nWhich airport has the worst delays? Discuss the metric you chose, and why you chose it to determine the “worst” airport. Your answer should include a summary table that lists (for each airport) the total number of flights, total number of delayed flights, proportion of delayed flights, and average delay time in hours.\nThe airport with the worst delays is clearly San Francisco California airport. 26% of flights at that airport are delayed. Which is 3% above any other airport that is listed. \n\n\nRead and format data\n# Include and execute your code here\nreplace_nan_df = fill_nan_df\n\n\n\n\nCode\n#select the four columns that are needed\nreplace_nan_df = replace_nan_df.groupby('airport_code').agg({'num_of_flights_total': 'sum', 'num_of_delays_total': 'sum', 'minutes_delayed_total': 'sum'})\n\n#code for new columns\n#total flights delayed divided by total flights\nproportion_of_flights = ((replace_nan_df.num_of_delays_total / replace_nan_df.num_of_flights_total))\n\n#minutes delayed total divided by total of flights\n#delay time in minutes to hours\naverage_delay_time_hours = (((replace_nan_df.minutes_delayed_total / replace_nan_df.num_of_flights_total) / 60))\n\n#appends new columns\nreplace_nan_df['proportion_of_flights'] = proportion_of_flights\nreplace_nan_df['average_delay_time'] = average_delay_time_hours\nreplace_nan_df\n\n\n\n\n\n\n\n\n\nnum_of_flights_total\nnum_of_delays_total\nminutes_delayed_total\nproportion_of_flights\naverage_delay_time\n\n\nairport_code\n\n\n\n\n\n\n\n\n\nATL\n4430047\n902443\n53983926\n0.203710\n0.203098\n\n\nDEN\n2513974\n468519\n25173381\n0.186366\n0.166890\n\n\nIAD\n851571\n168467\n10283478\n0.197831\n0.201265\n\n\nORD\n3597588\n830825\n56356129\n0.230939\n0.261083\n\n\nSAN\n917862\n175132\n8276248\n0.190804\n0.150281\n\n\nSFO\n1630945\n425604\n26550493\n0.260955\n0.271320\n\n\nSLC\n1403384\n205160\n10123371\n0.146189\n0.120226"
  },
  {
    "objectID": "Projects/project2.html#questiontask-3",
    "href": "Projects/project2.html#questiontask-3",
    "title": "Client Report - Project 2",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nWhat is the best month to fly if you want to avoid delays of any length? Discuss the metric you chose and why you chose it to calculate your answer. Include one chart to help support your answer, with the x-axis ordered by month. (To answer this question, you will need to remove any rows that are missing the Month variable.)\nThe best month to fly in to avoid delays is November. All of the other months are higher in total minutes delayed. I used the total minutes because it shows which month has the most time spent just sitting there and not getting to where you want to go.\n\n\nRead and format data\n# Include and execute your code here\n\n#this querys the data and only shows values that are not NaN\ntask_3_df = fill_nan_df\ntask_3_df = task_3_df.query(\"month != 'NaN'\")\n\n#this groups by the month and aggregates the minutes delayed total for each month\ntask_3_df = task_3_df.groupby('month').agg({'minutes_delayed_total': 'sum'})\n\n#this moves the month from being the index to being a normal column\ntask_3_df.reset_index(inplace=True)\n\n\n#this replaces the incorrect string spelling for FEBUARY as FEBRUARY\ntask_3_df['month'].replace('Febuary', 'February', inplace=True)\ntask_3_df\n\n#this is supposed to order the months in the correct order\n\n# month_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n\n# task_3_df['month'] = task_3_df['month'].astype('category')\n\n# task_3_df['month'] = task_3_df['month'].cat.set_categories(month_order, ordered=True)\n\n# task_3_df['month'] = pd.Categorical(task_3_df['month'], categories=month_order, ordered=True)\n\n# task_3_df = task_3_df.sort_values(by='month')\n# task_3_df\n\n\n\n\n\n\n\n\n\nmonth\nminutes_delayed_total\n\n\n\n\n0\nApril\n13667654\n\n\n1\nAugust\n16906565\n\n\n2\nDecember\n18821267\n\n\n3\nFebruary\n14753955\n\n\n4\nJanuary\n16152667\n\n\n5\nJuly\n20465456\n\n\n6\nJune\n20338750\n\n\n7\nMarch\n14942262\n\n\n8\nMay\n13637705\n\n\n9\nNovember\n11112089\n\n\n10\nOctober\n13109792\n\n\n11\nSeptember\n11495811\n\n\n\n\n\n\n\n\n\nplot example\naverage_delay = task_3_df['minutes_delayed_total'].mean()\n\nchart = px.bar(task_3_df,\n    x='month', \n    y=\"minutes_delayed_total\",\n    title='Total minutes delayed in each month'\n)\n\nchart.add_hline(y=average_delay, line_dash='solid', line_color='red')\n\nchart.show()"
  },
  {
    "objectID": "Projects/project2.html#questiontask-4",
    "href": "Projects/project2.html#questiontask-4",
    "title": "Client Report - Project 2",
    "section": "QUESTION|TASK 4",
    "text": "QUESTION|TASK 4\nAccording to the BTS website, the “Weather” category only accounts for severe weather delays. Mild weather delays are not counted in the “Weather” category, but are actually included in both the “NAS” and “Late-Arriving Aircraft” categories. Your job is to create a new column that calculates the total number of flights delayed by weather (both severe and mild). You will need to replace all the missing values in the Late Aircraft variable with the mean. Show your work by printing the first 5 rows of data in a table. Use these three rules for your calculations:\n100% of delayed flights in the Weather category are due to weather\n30% of all delayed flights in the Late-Arriving category are due to weather.\nFrom April to August, 40% of delayed flights in the NAS category are due to weather. The rest of the months, the proportion rises to 65%.\nAfter looking at the data it shows that the totals weather delays in quite substantial for each airport that is listed at the top of the data. Some have almost 4000 delays.\n\n\nRead and format data\n# Include and execute your code here\n\nweather = (df.assign(\n    severe = df.num_of_delays_weather, # no missing\n    nodla_nona = lambda x: (x.num_of_delays_late_aircraft\n        .replace(-999, np.nan)), #missing is -999\n    mild_late = lambda x: x.nodla_nona.fillna(x.nodla_nona.mean())*0.3,\n    mild = np.where(\n        df.month.isin(['April', 'May', 'June', 'July', 'August']), \n            df.num_of_delays_nas*0.4,\n            df.num_of_delays_nas*0.65),\n    weather = lambda x: x.severe + x.mild_late + x.mild,\n    proportion_weather_delay = lambda x: x.weather / x.num_of_delays_total,\n    proportion_weather_total = lambda x:  x.weather / x.num_of_flights_total,\n    weather_delays_total = lambda x: round(x.mild + x.severe))\n    .filter(['airport_code','month','year', 'severe','mild', 'mild_late',\n    'weather', 'proportion_weather_total', \n    'proportion_weather_delay', 'num_of_flights_total', 'num_of_delays_total', 'weather_delays_total']))\n\nweather.head()\n\n\n\n\n\n\n\n\n\nairport_code\nmonth\nyear\nsevere\nmild\nmild_late\nweather\nproportion_weather_total\nproportion_weather_delay\nnum_of_flights_total\nnum_of_delays_total\nweather_delays_total\n\n\n\n\n0\nATL\nJanuary\n2005.0\n448\n2988.70\n332.731222\n3769.431222\n0.107551\n0.451159\n35048\n8355\n3437.0\n\n\n1\nDEN\nJanuary\n2005.0\n233\n607.75\n278.400000\n1119.150000\n0.088212\n0.354948\n12687\n3153\n841.0\n\n\n2\nIAD\nJanuary\n2005.0\n61\n581.75\n317.400000\n960.150000\n0.077550\n0.395123\n12381\n2430\n643.0\n\n\n3\nORD\nJanuary\n2005.0\n306\n3519.75\n676.500000\n4502.250000\n0.159688\n0.490548\n28194\n9178\n3826.0\n\n\n4\nSAN\nJanuary\n2005.0\n56\n414.70\n204.000000\n674.700000\n0.092640\n0.345645\n7283\n1952\n471.0"
  },
  {
    "objectID": "Projects/project2.html#questiontask-5",
    "href": "Projects/project2.html#questiontask-5",
    "title": "Client Report - Project 2",
    "section": "QUESTION|TASK 5",
    "text": "QUESTION|TASK 5\nUsing the new weather variable calculated above, create a barplot showing the proportion of all flights that are delayed by weather at each airport. Discuss what you learn from this graph.\nFrom this graph you can see which airports have thet least amount of delays by weather and you can quickly see the two airports that have a lot of delays.\n\n\nplot example\n# Include and execute your code here\n\naverage_delay_by_airport = weather.groupby('airport_code')['proportion_weather_delay'].mean().reset_index()\n\nchart = px.bar(average_delay_by_airport.head(6),\n    x=\"airport_code\", \n    y=\"proportion_weather_delay\",\n    title=\"Weather Delay Proportion\"\n)\n\nchart.update_xaxes(title=\"Airport Code\")\nchart.update_yaxes(title=\"Weather Delay Percentage\")\n\nchart.show()"
  },
  {
    "objectID": "ml.html",
    "href": "ml.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "ml.html#title-2-header",
    "href": "ml.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "full_stack.html",
    "href": "full_stack.html",
    "title": "About Me",
    "section": "",
    "text": "Introduction\n\nMy name is Dale McBride, I am from a small town in Wyoming called Otto. I have always been interested in computers and have chosen to study Computer Science.\nI have always been active in Student Council as well as sports my entire life. Basketball is my favorite, but I also liked Football and Track.\nSome of my other interests are hunting and fishing. Generally, if it is outdoors I will like to do it.\n\nMarkDown Basics\n\n\n\n\n Back to top"
  },
  {
    "objectID": "competition.html",
    "href": "competition.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "competition.html#title-2-header",
    "href": "competition.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "cleansing.html",
    "href": "cleansing.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "cleansing.html#title-2-header",
    "href": "cleansing.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "exploration.html",
    "href": "exploration.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "exploration.html#title-2-header",
    "href": "exploration.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "index.html#title-2-header",
    "href": "index.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "Projects/project1.html",
    "href": "Projects/project1.html",
    "title": "Client Report - Project 1",
    "section": "",
    "text": "After analyzing the data some interesting insights developed. Some key insights were that each name has a specific trend that corrosponds with it. The trends seen with names can be related to events that happen. Such as a movie that has been released recently.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://raw.githubusercontent.com/byuidatascience/data4names/master/data-raw/names_year/names_year.csv\")"
  },
  {
    "objectID": "Projects/project1.html#elevator-pitch",
    "href": "Projects/project1.html#elevator-pitch",
    "title": "Client Report - Project 1",
    "section": "",
    "text": "After analyzing the data some interesting insights developed. Some key insights were that each name has a specific trend that corrosponds with it. The trends seen with names can be related to events that happen. Such as a movie that has been released recently.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://raw.githubusercontent.com/byuidatascience/data4names/master/data-raw/names_year/names_year.csv\")"
  },
  {
    "objectID": "Projects/project1.html#questiontask-1",
    "href": "Projects/project1.html#questiontask-1",
    "title": "Client Report - Project 1",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nHow does your name at your birth year compare to its use historically?\nMy name usage throughout the years has changed significantly as it nears my birth month. In 1958 is where the name peaked in usage and after that it dropped off significantly. When I was born in 2002 I was only one out of four hundred and ten named Dale that year.\n\n\nplot example\n# Include and execute your code here\nchart = px.line(df.query('name == \"Dale\"'),\n    x=\"year\", \n    y=\"Total\",\n    title = \"Usage of the name Dale\"\n)\nchart.add_annotation(x=1958, y=5735, text=\"Peak in name usgage 1958\", font=dict(size=10), arrowcolor=\"black\")\n\nchart.add_annotation(x=2002, y=410, text=\"My Birth Year 2002\", font=dict(size=10), arrowcolor=\"black\")\n\nchart.show()"
  },
  {
    "objectID": "Projects/project1.html#questiontask-2",
    "href": "Projects/project1.html#questiontask-2",
    "title": "Client Report - Project 1",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nIf you talked to someone named Brittany on the phone, what is your guess of his or her age? What ages would you not guess?\nIf I were to guess the age of someone Brittany I would guess the age 34. 1990 is when the most children were named Brittany. Making the age of 34 to be the best option. Ages I would not guess would be 45 or 14 because there are very few children named Brittany at those age points. \n\n\nplot example\n# Include and execute your code here\nchart = px.line(df.query('name == \"Brittany\"'),\n    x=\"year\", \n    y=\"Total\",\n    title = \"Brittany name usage\",\n    \n)\nchart.add_annotation(x=1990, y=32562, text=\"1990\", font=dict(size=10), arrowcolor=\"black\")\n\n\n\nchart.show()"
  },
  {
    "objectID": "Projects/project1.html#questiontask-3",
    "href": "Projects/project1.html#questiontask-3",
    "title": "Client Report - Project 1",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nMary, Martha, Peter, and Paul are all Christian names. From 1920 - 2000, compare the name usage of each of the four names. What trends do you notice?\nFrom 1920-1960 the name Mary was used a ton compared to the other names. They all collectively have a rise in usage at about 1950. After the year 1950 they all start to diwndle in there usage.\n\n\nplot example\n# Include and execute your code here\nchart = px.line(df.query('name == [\"Mary\", \"Martha\", \"Peter\", \"Paul\"]'),\n    x=\"year\", \n    y=\"Total\",\n    color = 'name',\n    title = 'Name Usage'\n    \n)\n\nchart.show()"
  },
  {
    "objectID": "Projects/project1.html#questiontask-4",
    "href": "Projects/project1.html#questiontask-4",
    "title": "Client Report - Project 1",
    "section": "QUESTION|TASK 4",
    "text": "QUESTION|TASK 4\nThink of a unique name from a famous movie. Plot the usage of that name and see how changes line up with the movie release. Does it look like the movie had an effect on usage?\nTaking a famous name such as Luke from Star Wars we can see that an increase begins to happen in the name usage after the year 1977. 1977 happens to be the same year that the movie for Star Wars came out. Leading me to beleive that there is a corrolation between the two.\n\n\nplot example\n# Include and execute your code here\nchart = px.bar(df.query('name == \"Luke\"'),\n    x=\"year\", \n    y=\"Total\",\n    title = 'Amount of children being named Luke'\n)\nchart.add_annotation(x=1977, y=1250, text=\"1977\", font=dict(size=14), arrowcolor=\"black\")\n\nchart.show()"
  },
  {
    "objectID": "Projects/project3.html",
    "href": "Projects/project3.html",
    "title": "Client Report - Project 3",
    "section": "",
    "text": "Research on BYU-Idaho alumni in MLB highlights a connection between atypical batting averages and shorter professional careers. It also reveals that teams investing more in player salaries, like the Boston Red Sox over the Baltimore Orioles, tend to experience better win rates. This suggests not only the financial dynamics of team performance but also the impact of individual player statistics on career longevity. These findings offer valuable insights into the strategic aspects of baseball, from player development to team management.\n\n\nRead and format project data\n# Include and execute your code here\nimport sys\nsqlite_file = \"C:\\\\Users\\\\dlmcb\\\\Documents\\\\GitHub\\\\school_work\\\\ds250\\\\lahmansbaseballdb.sqlite\"\nconn = sqlite3.connect(sqlite_file)"
  },
  {
    "objectID": "Projects/project3.html#elevator-pitch",
    "href": "Projects/project3.html#elevator-pitch",
    "title": "Client Report - Project 3",
    "section": "",
    "text": "Research on BYU-Idaho alumni in MLB highlights a connection between atypical batting averages and shorter professional careers. It also reveals that teams investing more in player salaries, like the Boston Red Sox over the Baltimore Orioles, tend to experience better win rates. This suggests not only the financial dynamics of team performance but also the impact of individual player statistics on career longevity. These findings offer valuable insights into the strategic aspects of baseball, from player development to team management.\n\n\nRead and format project data\n# Include and execute your code here\nimport sys\nsqlite_file = \"C:\\\\Users\\\\dlmcb\\\\Documents\\\\GitHub\\\\school_work\\\\ds250\\\\lahmansbaseballdb.sqlite\"\nconn = sqlite3.connect(sqlite_file)"
  },
  {
    "objectID": "Projects/project3.html#questiontask-1",
    "href": "Projects/project3.html#questiontask-1",
    "title": "Client Report - Project 3",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nWrite an SQL query to create a new dataframe about baseball players who attended BYU-Idaho. The new table should contain five columns: playerID, schoolID, salary, and the yearID/teamID associated with each salary. Order the table by salary (highest to lowest) and print out the table in your report.\nThe table about people who attended BYU-Idaho and played baseball shows that the highest salary that was paid was about $4,000,000 in 2014. While the lowest was at about $150,000 in 1997. Almost half of the players that attended BYU-Idaho made over 1 Million anually.\n\n\nRead and format data\n# Include and execute your code here\nq = '''\nSELECT DISTINCT cp.playerID, s.salary, s.yearID, s.teamID, cp.schoolID -- this selects the columns\nFROM collegeplaying AS cp \nLEFT JOIN salaries AS s \nON s.playerID = cp.PlayerID\nWHERE cp.schoolID = 'idbyuid'\nORDER BY s.salary DESC;\n'''\n\ndf1 = pd.read_sql_query(q,conn)\ndf1\n\n\n\n\n\n\n\n\n\nplayerID\nsalary\nyearID\nteamID\nschoolID\n\n\n\n\n0\nlindsma01\n4000000.0\n2014.0\nCHA\nidbyuid\n\n\n1\nlindsma01\n3600000.0\n2012.0\nBAL\nidbyuid\n\n\n2\nlindsma01\n2800000.0\n2011.0\nCOL\nidbyuid\n\n\n3\nlindsma01\n2300000.0\n2013.0\nCHA\nidbyuid\n\n\n4\nlindsma01\n1625000.0\n2010.0\nHOU\nidbyuid\n\n\n5\nstephga01\n1025000.0\n2001.0\nSLN\nidbyuid\n\n\n6\nstephga01\n900000.0\n2002.0\nSLN\nidbyuid\n\n\n7\nstephga01\n800000.0\n2003.0\nSLN\nidbyuid\n\n\n8\nstephga01\n550000.0\n2000.0\nSLN\nidbyuid\n\n\n9\nlindsma01\n410000.0\n2009.0\nFLO\nidbyuid\n\n\n10\nlindsma01\n395000.0\n2008.0\nFLO\nidbyuid\n\n\n11\nlindsma01\n380000.0\n2007.0\nFLO\nidbyuid\n\n\n12\nstephga01\n215000.0\n1999.0\nSLN\nidbyuid\n\n\n13\nstephga01\n185000.0\n1998.0\nPHI\nidbyuid\n\n\n14\nstephga01\n150000.0\n1997.0\nPHI\nidbyuid\n\n\n15\ncatetr01\nNaN\nNaN\nNone\nidbyuid"
  },
  {
    "objectID": "Projects/project3.html#questiontask-2",
    "href": "Projects/project3.html#questiontask-2",
    "title": "Client Report - Project 3",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nThis three-part question requires you to calculate batting average (number of hits divided by the number of at-bats)\nAfter looking at the tables we can see that over the course of a career an average of about .360 is a very good batting average. If the number is higher than that the player didn’t have a very long career or the just didn’t hit a lot. Such as a pitcher.\nWrite an SQL query that provides playerID, yearID, and batting average for players with at least 1 at bat that year. Sort the table from highest batting average to lowest, and then by playerid alphabetically. Show the top 5 results in your report.\n\n\nRead and format data\n# Include and execute your code here\nq = '''\nSELECT playerID, yearID, CAST(SUM(H) AS FLOAT) / CAST(SUM(AB) AS FLOAT) AS batting_average\nFROM Batting\nGROUP BY playerID, yearID\nHAVING SUM(AB) &gt;= 1\nORDER BY batting_average DESC, playerID ASC\nLIMIT 5;\n\n'''\ndf2 = pd.read_sql_query(q,conn)\ndf2\n\n\n\n\n\n\n\n\n\nplayerID\nyearID\nbatting_average\n\n\n\n\n0\nabernte02\n1960\n1.0\n\n\n1\nabramge01\n1923\n1.0\n\n\n2\nacklefr01\n1964\n1.0\n\n\n3\nalanirj01\n2019\n1.0\n\n\n4\nalberan01\n2017\n1.0\n\n\n\n\n\n\n\nUse the same query as above, but only include players with at least 10 at bats that year. Print the top 5 results.\n\n\nplot example\n# Include and execute your code here\nq = '''\nSELECT playerID, yearID, CAST(SUM(H) AS FLOAT) / CAST(SUM(AB) AS FLOAT) AS batting_average\nFROM Batting\nGROUP BY playerID, yearID\nHAVING SUM(AB) &gt;= 10\nORDER BY batting_average DESC, playerID ASC\nLIMIT 5;\n'''\ndf2 = pd.read_sql_query(q,conn)\ndf2\n\n\n\n\n\n\n\n\n\nplayerID\nyearID\nbatting_average\n\n\n\n\n0\nnymanny01\n1974\n0.642857\n\n\n1\ncarsoma01\n2013\n0.636364\n\n\n2\naltizda01\n1910\n0.600000\n\n\n3\nsilvech01\n1948\n0.571429\n\n\n4\npuccige01\n1930\n0.562500\n\n\n\n\n\n\n\nNow calculate the batting average for players over their entire careers (all years combined). Only include players with at least 100 at bats, and print the top 5 results.\n\n\ntable example\n# Include and execute your code here\nq = '''\nSELECT playerID, CAST(SUM(H) AS FLOAT) / CAST(SUM(AB) AS FLOAT) AS career_batting_average\nFROM Batting\nGROUP BY playerID\nHAVING SUM(AB) &gt;= 100\nORDER BY career_batting_average DESC\nLIMIT 5;\n\n'''\n\ndf2 = pd.read_sql_query(q,conn)\ndf2\n\n\n\n\n\n\n\n\n\nplayerID\ncareer_batting_average\n\n\n\n\n0\ncobbty01\n0.366299\n\n\n1\nbarnero01\n0.359682\n\n\n2\nhornsro01\n0.358497\n\n\n3\njacksjo01\n0.355752\n\n\n4\nmeyerle01\n0.355509"
  },
  {
    "objectID": "Projects/project3.html#questiontask-3",
    "href": "Projects/project3.html#questiontask-3",
    "title": "Client Report - Project 3",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nPick any two baseball teams and compare them using a metric of your choice (average salary, home runs, number of wins, etc). Write an SQL query to get the data you need, then make a graph using Plotly Express to visualize the comparison. What do you learn?\nLooking at the Baltimore Orioles and the Boston Red Sox after comparing the average salary of the two teams Boston pays a lot more than Baltimore. I wanted to see if a team pays more they will get more wins. From the two charts Boston started to catch up in pay and then paying more than Baltimore. Boston then started winning more and stayed above Baltimore in wins for a long time. In 2011 the salary peaked and declined afterwards. Interestingly the wins droped signifcantly as well after the pay went down.\n\n\nRead and format data\n# Include and execute your code here\nq = '''\nSELECT yearID AS Year, teamID AS Team, AVG(salary) AS AVG_Salary\nFROM salaries\nWHERE teamID = 'BAL' OR teamID = 'BOS'\nGROUP BY yearID, teamID\nORDER BY yearID\n'''\n\ndf3 = pd.read_sql_query(q,conn)\ndf3\n\n\n\n\n\n\n\n\n\nYear\nTeam\nAVG_Salary\n\n\n\n\n0\n1985\nBAL\n5.254869e+05\n\n\n1\n1985\nBOS\n4.359024e+05\n\n\n2\n1986\nBAL\n4.483192e+05\n\n\n3\n1986\nBOS\n4.966289e+05\n\n\n4\n1987\nBAL\n4.633424e+05\n\n\n...\n...\n...\n...\n\n\n59\n2014\nBOS\n4.484514e+06\n\n\n60\n2015\nBAL\n4.108744e+06\n\n\n61\n2015\nBOS\n5.659481e+06\n\n\n62\n2016\nBAL\n5.581498e+06\n\n\n63\n2016\nBOS\n6.501578e+06\n\n\n\n\n64 rows × 3 columns\n\n\n\n\n\nCode\nq = '''\nSELECT yearID AS Year, teamID AS Team, SUM(W) AS Wins\nFROM pitching\nWHERE teamID = 'BAL' OR teamID ='BOS'\nGROUP BY yearID, teamID\nHAVING yearID &gt;= 1985 AND yearID &lt;= 2016\nORDER BY yearID\n'''\n\ndf4 = pd.read_sql_query(q,conn)\ndf4\n\n\n\n\n\n\n\n\n\nYear\nTeam\nWins\n\n\n\n\n0\n1985\nBAL\n83\n\n\n1\n1985\nBOS\n81\n\n\n2\n1986\nBAL\n73\n\n\n3\n1986\nBOS\n95\n\n\n4\n1987\nBAL\n67\n\n\n...\n...\n...\n...\n\n\n59\n2014\nBOS\n71\n\n\n60\n2015\nBAL\n81\n\n\n61\n2015\nBOS\n78\n\n\n62\n2016\nBAL\n89\n\n\n63\n2016\nBOS\n93\n\n\n\n\n64 rows × 3 columns\n\n\n\ninclude figures in chunks and discuss your findings in the figure.\n\n\nplot example\n# Include and execute your code here\nchart = px.line(df3.head(70),\n    x=\"Year\", \n    y=\"AVG_Salary\",\n    color='Team',\n    title='Average Salary throughout the Years'\n)\n\nchart.add_annotation(x=2011, y=5991203, text=\"Salary Spike in 2011\", font=dict(size=10), arrowcolor=\"black\")\n\nchart.show()\n\n\n\n                                                \n\n\n\n\nplot example\n# Include and execute your code here\nchart = px.line(df4.head(200),\n    x=\"Year\", \n    y=\"Wins\",\n    color='Team',\n    title='Wins Each Year'\n)\n\nchart.add_annotation(x=2011, y=90, text=\"2011\", font=dict(size=10), arrowcolor=\"black\")\n\nchart.show()"
  },
  {
    "objectID": "Projects/project5.html",
    "href": "Projects/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "paste your elevator pitch here A SHORT (4-5 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS.\n\nHighlight the Questions and Tasks"
  },
  {
    "objectID": "Projects/project5.html#elevator-pitch",
    "href": "Projects/project5.html#elevator-pitch",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "paste your elevator pitch here A SHORT (4-5 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS.\n\nHighlight the Questions and Tasks"
  },
  {
    "objectID": "Projects/project5.html#questiontask-1",
    "href": "Projects/project5.html#questiontask-1",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nCOPY PASTE QUESTION|TASK 1 FROM THE PROJECT HERE\ntype your results and analysis here\n\ninclude figures in chunks and discuss your findings in the figure."
  },
  {
    "objectID": "Projects/project5.html#questiontask-2",
    "href": "Projects/project5.html#questiontask-2",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nCOPY PASTE QUESTION|TASK 2 FROM THE PROJECT HERE\ntype your results and analysis here\n\ninclude figures in chunks and discuss your findings in the figure."
  },
  {
    "objectID": "Projects/project5.html#questiontask-3",
    "href": "Projects/project5.html#questiontask-3",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nCOPY PASTE QUESTION|TASK 3 FROM THE PROJECT HERE\ntype your results and analysis here\n\ninclude figures in chunks and discuss your findings in the figure."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Dale McBride’s CV",
    "section": "",
    "text": "Computer Science, Life Learner.\n\ndalemcbride129@gmail.com | My Github page\n\n\n\n\nA Student at Brigham Young University Idaho\n\n\n\n\n2023-now Computer Science Degree\n2023 - now Business Minor\n2017-2021 High School Diploma\n\n\n\nHonor Society\n\nI met the academic requirements to be apart of the Honor Society\n\nAll State Basketball 2020-2021 All Conference Football 2020 Student Council Vice President - In this role I was asked to help organize trips and activities that we wanted to do at school.\n\n\n\nJuly 2023 - August 2023 Philpott Farm and Sawmill, Otto, WY\n\nFarm Hand\nI managed and took care of farm land and other tasks that were given to me.\n\nJune 2020 - August 2020 Meeteetse School, Meeteetse, WY\n\nMainenance Worker\nI maintained or cleaned the different systems and facilities that were on the campus."
  },
  {
    "objectID": "resume.html#currently",
    "href": "resume.html#currently",
    "title": "Dale McBride’s CV",
    "section": "",
    "text": "A Student at Brigham Young University Idaho"
  },
  {
    "objectID": "resume.html#education",
    "href": "resume.html#education",
    "title": "Dale McBride’s CV",
    "section": "",
    "text": "2023-now Computer Science Degree\n2023 - now Business Minor\n2017-2021 High School Diploma"
  },
  {
    "objectID": "resume.html#awardsinvolvement",
    "href": "resume.html#awardsinvolvement",
    "title": "Dale McBride’s CV",
    "section": "",
    "text": "Honor Society\n\nI met the academic requirements to be apart of the Honor Society\n\nAll State Basketball 2020-2021 All Conference Football 2020 Student Council Vice President - In this role I was asked to help organize trips and activities that we wanted to do at school."
  },
  {
    "objectID": "resume.html#previous-employment",
    "href": "resume.html#previous-employment",
    "title": "Dale McBride’s CV",
    "section": "",
    "text": "July 2023 - August 2023 Philpott Farm and Sawmill, Otto, WY\n\nFarm Hand\nI managed and took care of farm land and other tasks that were given to me.\n\nJune 2020 - August 2020 Meeteetse School, Meeteetse, WY\n\nMainenance Worker\nI maintained or cleaned the different systems and facilities that were on the campus."
  }
]